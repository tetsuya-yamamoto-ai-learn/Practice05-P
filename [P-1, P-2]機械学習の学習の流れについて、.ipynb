{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習の流れ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測対象のデータ（データセット）の収集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測対象のデータを収集する。データ数は多ければ多いほど訓練時の過学習を防ぐことが出来るので、データ数は多いとよい。\n",
    "\n",
    "また、この時収集されたデータについて、予測を行う対象を目的変数、予測を行うためのデータを説明変数と言う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト・訓練・検証データへの分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 訓練データ  \n",
    "  - モデルが学習するためのデータ\n",
    "  \n",
    "- 検証データ  \n",
    "  - 学習したモデルを評価するために使用するデータ\n",
    "  \n",
    "- テストデータ  \n",
    "  - 未知データへの汎化性能を評価するために使用するデータ  \n",
    "    (未知のデータとして扱うため、訓練時にleakageしないように扱うことが大事)\n",
    "    \n",
    "また訓練・検証データの扱いについて以下の方法がある\n",
    "\n",
    "- hold-out\n",
    "  - 訓練・検証データを2分割し、訓練→検証を実施して複数のモデルを評価、比較する方法\n",
    "  \n",
    "- k-cross-validation\n",
    "  - 訓練・検証データを複数に分割(以下k分割)し、そのうちのいくつかを訓練→検証することで、訓練・検証データすべてを用いてモデルを評価することができる。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実施"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習における学習とは訓練データに対して損失関数を設けて、その損失が最小になるようにモデルを修正することを学習という。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数は、モデルが学習を実施するときに使う評価指標の事。モデルの評価を行う関数なので、最終的なモデルの評価にも用いられる。\n",
    "\n",
    "回帰問題、分類問題に以下のような種類が存在する。\n",
    "\n",
    "- 回帰問題\n",
    "    - RMSE(二乗平均平方根誤差)\n",
    "      - データとモデルの予測値の誤差の二乗和平均の平方根をとったもの。値が大きくなれば誤差が大きい。\n",
    "        $$\n",
    "        RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left( y_{i} - \\hat{y_{i}} \\right)^{2}}\n",
    "        $$\n",
    "    - MAE(絶対平均誤差)\n",
    "      - データとモデルの予測値の誤差の絶対値和の平均をとったもの。値が大きくなれば誤差は大きい。\n",
    "        $$\n",
    "      n MAE = \\frac{1}{n}\\sum_{i=1}^{n}| y_{i} - \\hat{y_{i}} |\n",
    "        $$\n",
    "    - R2 Score(決定係数)\n",
    "      - 式については難しいので省略。値が0~1で示される。係数なので、データの値の大きさに値が左右されないため、他のデータに対して学習と比較してどれくらい予測がうまくできているかを知ることができる。\n",
    "　      $$\n",
    "  　    R^{2} = 1 -\\frac{\\sum_{i=1}^{n}\\left(y_{i} - \\hat{y_{i}}\\right)^{2}}{\\sum_{i=1}^{n}\\left(y_{i} - \\bar{y} \\right)^{2}}\n",
    "    　  $$\n",
    "       \n",
    "- 分類問題  \n",
    "    以下TP(True Positive),TN(True Negative), FP(False Positive(実際はNegative)),FN(False Negative(実際はPositive))で式を示す\n",
    "    - 正答率(Accuracy)：予測がどれだけ正解していたかを評価する値。\n",
    "        $$\n",
    "        Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}\n",
    "        $$\n",
    "    - 適合率(Precision)：陽と予測したものが実際どれだけ陽だったかを評価する値。\n",
    "        $$\n",
    "        Precision = \\frac{TP}{TP+FP}\n",
    "        $$\n",
    "    - 適応率：実際に陽なデータをどれだけ陽と予測できたかを評価する値。\n",
    "        $$\n",
    "        Recall = \\frac{TP}{TP+FN}\n",
    "        $$\n",
    "    - F値：PrecisionとRecall、両方ともいい感じなやつ（式は省略）。\n",
    "    \n",
    "    - 交差エントロピー誤差：\n",
    "        - モデルが予測した確率と、正解ラベルの間のエントロピーを計算したもの。陽陰の二値だけでなく、モデルが予測した結果を確率として示していることで評価できるので、モデルの学習がどれだけ進んでいるか評価する事もできる。\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの種類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T08:20:15.261618Z",
     "start_time": "2019-10-10T08:20:15.245661Z"
    }
   },
   "source": [
    "モデルは、学習を行う際に、データをどのように回帰させるかを決定したもので、ある意味、最終的にデータがこのように推移していると予測していることに等しい。\n",
    "\n",
    "- 線形回帰(Linear Regression)\n",
    "- ロジスティック回帰(Logistic Regression)←回帰とあるけど分類問題\n",
    "- SVM←SVC分類、SVR回帰\n",
    "- ニューラルネット\n",
    "\n",
    "などなど"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習における学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習における学習とは、最適化を行う際に基準となる損失関数を設け、その損失関数が小さくなるように重みを調整していく事を学習という。  \n",
    "この重みを調整する際に、誤差逆伝播法を用いて、損失関数に対する各重みの勾配を計算し、損失関数が減少するように重みを調整することで損失関数を減らしていく手法の事を勾配降下法という。これを繰り返して学習を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バッチ学習とミニバッチ学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配降下法は訓練データから勾配を計算し、その勾配に対して学習率と呼ばれる係数をかけて、学習を行う。  \n",
    "\n",
    "この勾配降下法において、一度重みを調整する際に使用する学習データのことをバッチ(batch)と呼ぶ。また、訓練データ全てを1単位としてエポック(epoch)と呼ぶ。\n",
    "\n",
    "勾配降下法には主にバッチ勾配降下法、ミニバッチ勾配降下法、確率的勾配降下法（オンライン勾配降下法）がある。  \n",
    "- バッチ勾配降下法: 一度の学習にすべての訓練データを用いて勾配を計算する手法\n",
    "- 確率的勾配降下法: 一度の学習に一つの訓練データだけを用いて勾配を計算する手法\n",
    "- ミニバッチ勾配降下法：バッチの大きさを任意に決めて、その単位で勾配を計算する手法\n",
    "\n",
    "特徴としては以下の通り\n",
    "\n",
    "| 種類 | バッチ勾配降下法 | ミニバッチ勾配降下法 | 確率的勾配降下法 |  \n",
    "| :---: | :--- | :--- | :--- |  \n",
    "| バッチの大きさ|大きい | ほどほど | 小さい |\n",
    "| 一度の学習の精度 | 高い | ほどほど | 低い |\n",
    "| 一度の学習の計算コスト | 高い | ほどほど | 低い |\n",
    "\n",
    "確率勾配降下法は一度の計算コストが低いが、データによっては変な方向（勾配）に学習が行われてしまう可能性がある。  \n",
    "\n",
    "一方、バッチ勾配降下法は、勾配が多くのデータの平均をとって求められるため、良い方向に学習が行われる可能性が高い一方で、同じような結果を出すデータに対しても一度すべて計算してから学習が行われるため、無駄な計算が多いことがある。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
